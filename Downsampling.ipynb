{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d015783b-ba8b-4083-930f-6ca836e5af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, layers\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c27e6-0998-4c8e-9ceb-7f63ac447f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BicubicDownSample(nn.Module):\n",
    "    def bicubic_kernel(self, x, a=-0.50):\n",
    "        \"\"\"\n",
    "        This equation is exactly copied from the website below:\n",
    "        https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic\n",
    "        \"\"\"\n",
    "        abs_x = torch.abs(x)\n",
    "        if abs_x <= 1.:\n",
    "            return (a + 2.) * torch.pow(abs_x, 3.) - (a + 3.) * torch.pow(abs_x, 2.) + 1\n",
    "        elif 1. < abs_x < 2.:\n",
    "            return a * torch.pow(abs_x, 3) - 5. * a * torch.pow(abs_x, 2.) + 8. * a * abs_x - 4. * a\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def __init__(self, factor=4, cuda=True, padding='reflect'):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        size = factor * 4\n",
    "        k = torch.tensor([self.bicubic_kernel((i - torch.floor(torch.tensor(size / 2)) + 0.5) / factor)\n",
    "                          for i in range(size)], dtype=torch.float32)\n",
    "        k = k / torch.sum(k)\n",
    "        # k = torch.einsum('i,j->ij', (k, k))\n",
    "        k1 = torch.reshape(k, shape=(1, 1, size, 1))\n",
    "        self.k1 = torch.cat([k1, k1, k1], dim=0)\n",
    "        k2 = torch.reshape(k, shape=(1, 1, 1, size))\n",
    "        self.k2 = torch.cat([k2, k2, k2], dim=0)\n",
    "        self.cuda = '.cuda' if cuda else ''\n",
    "        self.padding = padding\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, nhwc=False, clip_round=False, byte_output=False):\n",
    "        # x = torch.from_numpy(x).type('torch.FloatTensor')\n",
    "        filter_height = self.factor * 4\n",
    "        filter_width = self.factor * 4\n",
    "        stride = self.factor\n",
    "\n",
    "        pad_along_height = max(filter_height - stride, 0)\n",
    "        pad_along_width = max(filter_width - stride, 0)\n",
    "        filters1 = self.k1.type('torch{}.FloatTensor'.format(self.cuda))\n",
    "        filters2 = self.k2.type('torch{}.FloatTensor'.format(self.cuda))\n",
    "\n",
    "        # compute actual padding values for each side\n",
    "        pad_top = pad_along_height // 2\n",
    "        pad_bottom = pad_along_height - pad_top\n",
    "        pad_left = pad_along_width // 2\n",
    "        pad_right = pad_along_width - pad_left\n",
    "\n",
    "        # apply mirror padding\n",
    "        if nhwc:\n",
    "            x = torch.transpose(torch.transpose(\n",
    "                x, 2, 3), 1, 2)   # NHWC to NCHW\n",
    "\n",
    "        # downscaling performed by 1-d convolution\n",
    "        x = F.pad(x, (0, 0, pad_top, pad_bottom), self.padding)\n",
    "        x = F.conv2d(input=x, weight=filters1, stride=(stride, 1), groups=3)\n",
    "        if clip_round:\n",
    "            x = torch.clamp(torch.round(x), 0.0, 255.)\n",
    "\n",
    "        x = F.pad(x, (pad_left, pad_right, 0, 0), self.padding)\n",
    "        x = F.conv2d(input=x, weight=filters2, stride=(1, stride), groups=3)\n",
    "        if clip_round:\n",
    "            x = torch.clamp(torch.round(x), 0.0, 255.)\n",
    "\n",
    "        if nhwc:\n",
    "            x = torch.transpose(torch.transpose(x, 1, 3), 1, 2)\n",
    "        if byte_output:\n",
    "            return x.type('torch.ByteTensor'.format(self.cuda))\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "with h5py.File('Galaxy10_DECals_downsampled.h5', 'r') as f:\n",
    "#with h5py.File('Galaxy10_DECals.h5', 'r') as f:\n",
    "    imgs256 = np.array(f['images']) # read images\n",
    "\n",
    "    #First we delete these three images because they contain only NaN\n",
    "    imgs256 = np.delete(imgs256, 15422, 0)\n",
    "    imgs256 = np.delete(imgs256, 12659, 0)\n",
    "    imgs256 = np.delete(imgs256, 11492, 0)\n",
    "    labels = np.array(f['ans']) # read labels\n",
    "    labels = np.delete(labels, 15422, 0)\n",
    "    labels = np.delete(labels, 12659, 0)\n",
    "    labels = np.delete(labels, 11492, 0)\n",
    "    label_text = [ 'Disturbed Galaxies',\n",
    "                    'Merging Galaxies',\n",
    "                    'Round Smooth Galaxies',\n",
    "                    'In-between Round Smooth Galaxies',\n",
    "                    'Cigar Shaped Smooth Galaxies',\n",
    "                    'Barred Spiral Galaxies',\n",
    "                    'Unbarred Tight Spiral Galaxies',\n",
    "                    'Unbarred Loose Spiral Galaxies',\n",
    "                    'Edge-on Galaxies without Bulge',\n",
    "                    'Edge-on Galaxies with Bulge',]\n",
    "    \n",
    "print(np.shape(labels))\n",
    "print(np.shape(imgs256))\n",
    "\"\"\"\n",
    "#DOWNSAMPLING TO 128\n",
    "# Initialize the BicubicDownSample module\n",
    "downsampler2 = BicubicDownSample(factor=2, cuda=False)  # Set cuda=True if using GPU\n",
    "\n",
    "# Create an array to hold the downsampled images\n",
    "num_images = imgs256.shape[0]\n",
    "imgs128 = np.zeros((num_images, 128, 128, 3), dtype=np.float32)  # Assuming the target size is (64, 64, 3)\n",
    "\n",
    "# Loop over each image and downsample\n",
    "for i in range(num_images):\n",
    "    image_np = imgs256[i]  # Shape (256, 256, 3)\n",
    "    image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float()  # Shape (1, 3, 256, 256)\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients\n",
    "        downsampled_tensor = downsampler2(image_tensor)\n",
    "\n",
    "    downsampled_image_tensor = downsampled_tensor.squeeze(0)  # Shape (3, 64, 64)\n",
    "    downsampled_image_np = downsampled_image_tensor.permute(1, 2, 0).numpy()  # Shape (64, 64, 3)\n",
    "\n",
    "    imgs128[i] = downsampled_image_np\n",
    "\n",
    "#DOWNSAMPLING TO 64\n",
    "# Initialize the BicubicDownSample module\n",
    "downsampler4 = BicubicDownSample(factor=4, cuda=False)  # Set cuda=True if using GPU\n",
    "\n",
    "# Create an array to hold the downsampled images\n",
    "num_images = imgs256.shape[0]\n",
    "imgs64 = np.zeros((num_images, 64, 64, 3), dtype=np.float32)  # Assuming the target size is (64, 64, 3)\n",
    "\n",
    "# Loop over each image and downsample\n",
    "for i in range(num_images):\n",
    "    image_np = imgs256[i]  # Shape (256, 256, 3)\n",
    "    image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float()  # Shape (1, 3, 256, 256)\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients\n",
    "        downsampled_tensor = downsampler4(image_tensor)\n",
    "\n",
    "    downsampled_image_tensor = downsampled_tensor.squeeze(0)  # Shape (3, 64, 64)\n",
    "    downsampled_image_np = downsampled_image_tensor.permute(1, 2, 0).numpy()  # Shape (64, 64, 3)\n",
    "\n",
    "    imgs64[i] = downsampled_image_np\n",
    "\"\"\"\n",
    "#DOWNSAMPLING TO 32\n",
    "# Initialize the BicubicDownSample module\n",
    "downsampler8 = BicubicDownSample(factor=2, cuda=False)  # Set cuda=True if using GPU\n",
    "\n",
    "# Create an array to hold the downsampled images\n",
    "num_images = imgs256.shape[0]\n",
    "imgs32 = np.zeros((num_images, 32, 32, 3), dtype=np.float32)  # Assuming the target size is (64, 64, 3)\n",
    "\n",
    "# Loop over each image and downsample\n",
    "for i in range(num_images):\n",
    "    image_np = imgs256[i]  # Shape (256, 256, 3)\n",
    "    image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float()  # Shape (1, 3, 256, 256)\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients\n",
    "        downsampled_tensor = downsampler8(image_tensor)\n",
    "\n",
    "    downsampled_image_tensor = downsampled_tensor.squeeze(0)  # Shape (3, 64, 64)\n",
    "    downsampled_image_np = downsampled_image_tensor.permute(1, 2, 0).numpy()  # Shape (64, 64, 3)\n",
    "\n",
    "    imgs32[i] = downsampled_image_np\n",
    "\n",
    "# Save the downsampled images to an HDF5 file (optional)\n",
    "#with h5py.File('Galaxy10_DECals_128.h5', 'w') as f:\n",
    "#    f.create_dataset('images', data=imgs128)\n",
    "\n",
    "#print(np.shape(imgs128))\n",
    "#print(np.shape(imgs64))\n",
    "print(np.shape(imgs32))\n",
    "\n",
    "# Save the cleaned data to a new HDF5 file\n",
    "with h5py.File('Galaxy10_DECals_32.h5', 'w') as f:\n",
    "    f.create_dataset('images', data=imgs32)\n",
    "    f.create_dataset('ans', data=labels)\n",
    "    # Optionally, you can also store the label_text\n",
    "    dt = h5py.string_dtype(encoding='utf-8')\n",
    "    f.create_dataset('label_text', data=label_text, dtype=dt)\n",
    "\n",
    "print(\"Data has been saved to Galaxy10_DECals_downsampled_cleaned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08885727-2e86-4e6f-891c-3cdbb81a3b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
